{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(r\"C:\\Users\\scanimage\\Documents\\JJM\\post_cnmfe_analysis\")\n",
    "import dlc_utils as dlc\n",
    "import os\n",
    "import datetime\n",
    "import math\n",
    "import time \n",
    "from tqdm import tqdm\n",
    "from matplotlib.dates import DateFormatter, date2num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scanimage\\AppData\\Local\\Temp\\ipykernel_15120\\912229180.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = r\"F:\\\\JJM\\\\behavCam_videos_for_analysis\\\\v4_fenobaminjections\\\\\"\n",
    "ezTrack_location_files = glob.glob(data_folder+ r\"*\\\\*LocationOutput.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ezTrack_location_files = glob.glob(data_folder+ r\"\\\\*GRIN*\\\\\" + '*LocationOutput.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ezTrack_location_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.14_00_14_00_13\\\\DIO_r2.14_00_14_00_13combined_LocationOutput.csv',\n",
       " 'F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.14_00_17_25_26\\\\DIO_r2.14_00_17_25_26_combined_LocationOutput.csv',\n",
       " 'F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.14_01_14_30_28\\\\DIO_r2.14_01_14_30_28combined_LocationOutput.csv',\n",
       " 'F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.14_01_17_40_46\\\\DIO_r2.14_01_17_40_46_combined_LocationOutput.csv',\n",
       " 'F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.14_02_18_11_01\\\\DIO_r2.14_02_18_11_01_combined_LocationOutput.csv',\n",
       " 'F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.19_13_45_01\\\\concactenated_behavCam00_behavCam27_LocationOutput.csv',\n",
       " 'F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.19_14_15_20\\\\concactenated_behavCam00_behavCam27_LocationOutput.csv',\n",
       " 'F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.19_16_04_27\\\\concactenated_behavCam00_behavCam27_LocationOutput.csv',\n",
       " 'F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.19_16_34_31\\\\concactenated_behavCam00_behavCam27_LocationOutput.csv',\n",
       " 'F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.7_15_20_30\\\\DIO_r2.7_15_20_30_combined_LocationOutput.csv',\n",
       " 'F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.7_15_51_07\\\\DIO_r2.7_15_51_07_combined_LocationOutput.csv',\n",
       " 'F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.7_17_00_12\\\\DIO_r2.7_17_00_12_combined_LocationOutput.csv',\n",
       " 'F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.7_17_30_50\\\\DIO_r2.7_17_30_50_combined_LocationOutput.csv',\n",
       " 'F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.8_16_00_28\\\\DIO_r2.8_16_00_28_combined_LocationOutput.csv',\n",
       " 'F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.8_16_30_39\\\\DIO_r2.8_16_30_39_combined_LocationOutput.csv',\n",
       " 'F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.8_16_45_11\\\\DIO_r2.8_16_45_11combined_LocationOutput.csv',\n",
       " 'F:\\\\\\\\JJM\\\\\\\\behavCam_videos_for_analysis\\\\\\\\v4_fenobaminjections\\\\DIO_r2.8_17_16_03\\\\DIO_r2.8_17_16_03_combined_LocationOutput.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ezTrack_location_files[0:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignBinVelocity(sessionPath, savePath, downSampleFactorForVelocity, medianFilter, velocityBins):\n",
    "\n",
    "    #'\\\\'.join(sessionPath.split(os.sep)[:-1])+'\\\\timestamp.dat'\n",
    "    print(sessionPath.split(os.sep)[:-1])\n",
    "    # load eZ track output and behavior camera timestamps from miniscope software \n",
    "    ezTrackOutput = pd.read_csv(sessionPath)\n",
    "    timestampfile = pd.read_table('\\\\'.join(sessionPath.split(os.sep)[:-1])+'\\\\timestamps.csv', delimiter=',')\n",
    "    miniscope_timestampfile = pd.read_table('\\\\'.join(sessionPath.split(os.sep)[:-1])+'\\\\timestampsMiniscope.csv', delimiter=',')\n",
    "    \n",
    "    frame_rate=15\n",
    "    timestampfile_td = timestampfile.set_index(pd.to_timedelta(np.linspace(0, (len(timestampfile)-1)*(1/frame_rate), len(timestampfile)), unit='s'), drop=False)\n",
    "    behavCamTimeStampsDownsampled = timestampfile_td.resample('.2S').bfill()\n",
    "    behavCamTimeStampsMedian = behavCamTimeStampsDownsampled.resample('1S').median()\n",
    "    behavCamTimeStampsResampled = behavCamTimeStampsMedian.resample('.2S').bfill()\n",
    "    \n",
    "    frame_rate=20\n",
    "    miniscopetimestamp_td = miniscope_timestampfile.set_index(pd.to_timedelta(np.linspace(0, (len(miniscope_timestampfile)-1)*(1/frame_rate), len(miniscope_timestampfile)), unit='s'), drop=False)\n",
    "    miniscopeTimeStampsDownsampled = miniscopetimestamp_td.resample('.2S').bfill()\n",
    "    miniscopeTimeStampsMedian = miniscopeTimeStampsDownsampled.resample('1S').median()\n",
    "    miniscopeTimeStampsResampled = miniscopeTimeStampsMedian.resample('.2S').bfill()\n",
    "    \n",
    "    \n",
    "    behavCam_frames = []\n",
    "    sys_clock_behavCam = []\n",
    "    #create \"key\" for aligning miniscope frames to timestamp file\n",
    "    #then create behavior TD and align\n",
    "    for msCam_frame in tqdm(range(0, len(miniscopeTimeStampsResampled['Frame Number']))):\n",
    "        #get sys clock time of each miniscope recorded frame\n",
    "        #sys_clock_msCam = time_stamps['sysClock'].loc[msCam_frame]\n",
    "        #find behav cam frame closest to sys clock time of ms frame\n",
    "        behavCam_frame = list(behavCamTimeStampsResampled.iloc[(behavCamTimeStampsResampled['Time Stamp (ms)']-miniscopeTimeStampsResampled['Time Stamp (ms)'].iloc[msCam_frame]).abs().argsort()[:1]].index)[0]\n",
    "        behavCam_frames.append(behavCam_frame)\n",
    "        sys_clock_behavCam.append(behavCamTimeStampsResampled.loc[behavCam_frame]['Time Stamp (ms)'])\n",
    "\n",
    "    behavCamIdxToAlign = [behavCamTimeStampsResampled.index.get_loc(idx) for idx in behavCam_frames]\n",
    "    #ezTrackOutput\n",
    "\n",
    "    # separate behavCam time stamps\n",
    "    behavCamTimeStamps = timestampfile['Time Stamp (ms)']\n",
    "    #behavCamTimeStamps['frameNum'][0:len(ezTrackOutput)]\n",
    "    # get times of frames\n",
    "    behavCamTimes = behavCamTimeStamps\n",
    "    # set 1st frame to 0 \n",
    "    behavCamTimes[1] = 0 \n",
    "    # reset index to 0 \n",
    "    #behavCamTimes = behavCamTimes.reset_index()\n",
    "\n",
    "    # delta T between frames for analyzed videos \n",
    "    behavCamFrameTimeDelta = behavCamTimes.diff()[0:len(ezTrackOutput)]\n",
    "    \n",
    "    # get velocity from frame times \n",
    "    velocity = abs(ezTrackOutput['Distance_cm'].diff())/(behavCamFrameTimeDelta/1000)\n",
    "\n",
    "    # data frame of mouse velocity \n",
    "    veloctiyDataFrame = pd.concat([ezTrackOutput[['Frame', 'X', 'Y', 'Distance_px', 'Distance_cm']], \n",
    "                               behavCamTimes[0:len(ezTrackOutput)],\n",
    "                               pd.DataFrame(velocity, columns=['Velocity'])], axis=1)\n",
    "    \n",
    "    #calculate frame rate \n",
    "    frame_rate = int(1000/veloctiyDataFrame['Time Stamp (ms)'].diff().mean())\n",
    "\n",
    "    # create time delta for behavior index\n",
    "    # behavCam for v3 should record at 30 fps, can verify in timestamp file, check this is set correctly in concactenated videos\n",
    "    veloctiyDataFrame = veloctiyDataFrame.set_index(pd.to_timedelta(np.linspace(0, (len(veloctiyDataFrame)-1)*(1/frame_rate), len(veloctiyDataFrame)), unit='s'))\n",
    "    veloctiyDataFrame\n",
    "\n",
    "    #len(veloctiyDataFrame)\n",
    "\n",
    "    ## smooth velocity by downsampling to 5Hz to calculate distance travelled \n",
    "    downsampledDataFrame = veloctiyDataFrame.resample('.2S').mean()[['X', 'Y']]\n",
    "    # calculate new euclidean distance based on mean values here \n",
    "\n",
    "\n",
    "    cmPerPixel = veloctiyDataFrame['Distance_cm'][1]/veloctiyDataFrame['Distance_px'][1]\n",
    "\n",
    "    print(cmPerPixel)\n",
    "\n",
    "    def euclideanDistance(row):\n",
    "        return(math.sqrt(row['X']**2+row['Y']**2))\n",
    "\n",
    "    def smoothedVelocity(row, cmPerPixel):\n",
    "        #euclidean distance divided by sampling rate, multiplied by cm/pixel\n",
    "        return((math.sqrt(row['X']**2+row['Y']**2)/.2)*cmPerPixel)\n",
    "    \n",
    "    downsampledDataFrame['smoothedVelocity'] = downsampledDataFrame.diff().apply(lambda row : smoothedVelocity(row, cmPerPixel), axis=1)\n",
    "\n",
    "    downsampledDataFrame\n",
    "\n",
    "    #downsample once more to 2S as a \"median filter\"\n",
    "    downsampledMedian = downsampledDataFrame.resample(medianFilter).median()\n",
    "\n",
    "    #resample to 5Hz for alignment with imaging data\n",
    "    resampledToAlign = downsampledMedian.resample('.2S').bfill()\n",
    "    ## remove frames here to align with miniscope df \n",
    "    velocity_resampled = resampledToAlign.iloc[behavCamIdxToAlign]\n",
    "    \n",
    "    \n",
    "    ## save speed bins\n",
    "    #velocity_resampled[(velocity_resampled['smoothedVelocity']>0) & (velocity_resampled['smoothedVelocity']<0.5)]\n",
    "\n",
    "    # for \"rest\" analysis maybe further split < 0.5 cm/sec bins e.g. (0, 0.25) (0, 0.5)\n",
    "\n",
    "    # define velocity bins and save output to csv files for clustering analysis\n",
    "    \n",
    "    v_bin_dict = {}\n",
    "\n",
    "    #save data frames of bin indicies in dictionary\n",
    "    for bin_idx in range(len(velocityBins)):\n",
    "        v_bin_dict[bin_idx]=pd.DataFrame([velocity_resampled.index.get_loc(velocity_resampled[(velocity_resampled['smoothedVelocity']>velocityBins[bin_idx][0]) & (velocity_resampled['smoothedVelocity']<velocityBins[bin_idx][1])].index[i]) \n",
    "         for i in range(len(velocity_resampled[(velocity_resampled['smoothedVelocity']>velocityBins[bin_idx][0]) & (velocity_resampled['smoothedVelocity']<velocityBins[bin_idx][1])].index))], columns=['Indicies'])\n",
    "    #save to csv files\n",
    "    for bin_idx in range(len(velocityBins)):\n",
    "        v_bin_dict[bin_idx].to_csv(savePath+os.path.split(sessionPath)[0].split('\\\\')[-1]+'_velocityBin'+str(bin_idx)+'.csv')\n",
    "    \n",
    "    return(v_bin_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F:', '', 'JJM', '', 'behavCam_videos_for_analysis', '', 'v4_fenobaminjections', 'DIO_r2.14_00_14_00_13']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8921/8921 [00:06<00:00, 1302.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12252631327288699\n",
      "['F:', '', 'JJM', '', 'behavCam_videos_for_analysis', '', 'v4_fenobaminjections', 'DIO_r2.14_00_17_25_26']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4466/4466 [00:03<00:00, 1459.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11795811623765394\n",
      "['F:', '', 'JJM', '', 'behavCam_videos_for_analysis', '', 'v4_fenobaminjections', 'DIO_r2.14_01_14_30_28']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8916/8916 [00:07<00:00, 1253.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12101356237363664\n",
      "['F:', '', 'JJM', '', 'behavCam_videos_for_analysis', '', 'v4_fenobaminjections', 'DIO_r2.14_01_17_40_46']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8921/8921 [00:07<00:00, 1274.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11852554225435583\n",
      "['F:', '', 'JJM', '', 'behavCam_videos_for_analysis', '', 'v4_fenobaminjections', 'DIO_r2.14_02_18_11_01']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 5341/5341 [00:03<00:00, 1422.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1185299967621067\n",
      "['F:', '', 'JJM', '', 'behavCam_videos_for_analysis', '', 'v4_fenobaminjections', 'DIO_r2.19_13_45_01']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8916/8916 [00:06<00:00, 1275.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12651275310264815\n",
      "['F:', '', 'JJM', '', 'behavCam_videos_for_analysis', '', 'v4_fenobaminjections', 'DIO_r2.19_14_15_20']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8916/8916 [00:06<00:00, 1278.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1267407533346728\n",
      "['F:', '', 'JJM', '', 'behavCam_videos_for_analysis', '', 'v4_fenobaminjections', 'DIO_r2.19_16_04_27']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8891/8891 [00:06<00:00, 1296.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12757364266311538\n",
      "['F:', '', 'JJM', '', 'behavCam_videos_for_analysis', '', 'v4_fenobaminjections', 'DIO_r2.19_16_34_31']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8891/8891 [00:06<00:00, 1287.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12664522964486824\n",
      "['F:', '', 'JJM', '', 'behavCam_videos_for_analysis', '', 'v4_fenobaminjections', 'DIO_r2.7_15_20_30']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8921/8921 [00:07<00:00, 1259.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11734536170992109\n",
      "['F:', '', 'JJM', '', 'behavCam_videos_for_analysis', '', 'v4_fenobaminjections', 'DIO_r2.7_15_51_07']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8916/8916 [00:06<00:00, 1301.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11615685141272226\n",
      "['F:', '', 'JJM', '', 'behavCam_videos_for_analysis', '', 'v4_fenobaminjections', 'DIO_r2.7_17_00_12']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8891/8891 [00:06<00:00, 1286.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12346719988436243\n",
      "['F:', '', 'JJM', '', 'behavCam_videos_for_analysis', '', 'v4_fenobaminjections', 'DIO_r2.7_17_30_50']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8891/8891 [00:06<00:00, 1287.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1261701512195422\n",
      "['F:', '', 'JJM', '', 'behavCam_videos_for_analysis', '', 'v4_fenobaminjections', 'DIO_r2.8_16_00_28']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8896/8896 [00:06<00:00, 1291.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12078966983174881\n",
      "['F:', '', 'JJM', '', 'behavCam_videos_for_analysis', '', 'v4_fenobaminjections', 'DIO_r2.8_16_30_39']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8896/8896 [00:06<00:00, 1285.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12156324401893985\n",
      "['F:', '', 'JJM', '', 'behavCam_videos_for_analysis', '', 'v4_fenobaminjections', 'DIO_r2.8_16_45_11']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8921/8921 [00:06<00:00, 1305.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1268858800773694\n"
     ]
    }
   ],
   "source": [
    "savePath = r'F:\\\\JJM\\\\miniscope_analysis\\\\mGluR5_NAM\\\\clustering_analysis\\\\frames_subset_'+time.strftime(\"%a_%d_%b_%Y_%H_%M_%S\")+'\\\\'\n",
    "os.mkdir(savePath)\n",
    "downSampleFactorForVelocity = '.2S'\n",
    "medianFilter = '1S'\n",
    "vBins = [(0, 0.75), (0.75, 1.5), (1.5, 2.5), (2.5, 6), (6, 10), (10, math.inf)]\n",
    "batch_output = {}\n",
    "for sessionPath in  ezTrack_location_files[0:16]:\n",
    "    v_bin_dict = alignBinVelocity(sessionPath, savePath, downSampleFactorForVelocity, medianFilter, vBins)\n",
    "    batch_output[os.path.split(sessionPath)[0].split('\\\\')[-1]]=v_bin_dict\n",
    "    \n",
    "params = pd.DataFrame({'downSampleFactorForVelocity': downSampleFactorForVelocity, 'medianFilter': medianFilter}, index=['params'])\n",
    "params.to_csv(savePath+'\\\\'+'params.csv')\n",
    "vBins = pd.DataFrame(vBins)\n",
    "vBins.to_csv(savePath+'\\\\'+'vBins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## velocity dataframe plot unsmoothed\n",
    "xRangeFrames=(0,58000)\n",
    "y = veloctiyDataFrame['Velocity'][xRangeFrames[0]:xRangeFrames[1]]\n",
    "#recording_start_time = datetime.datetime.fromtimestamp(abs(timestampfile[timestampfile['camNum'] == 1]['sysClock'][1]))\n",
    "#plot x axis time\n",
    "recording_start_time = datetime.datetime(1970, 1, 1, hour=0, minute=0, second=0, microsecond=0)\n",
    "x = [recording_start_time+veloctiyDataFrame.index[i] for i in range(len(veloctiyDataFrame.index))][xRangeFrames[0]:xRangeFrames[1]]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax2 = ax1.twiny()\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "\n",
    "myFmt = DateFormatter(\"%M:%S:%ms\")\n",
    "ax1.xaxis.set_major_formatter(myFmt)\n",
    "ax1.plot(x, y)\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "# Move twinned axis ticks and label from top to bottom\n",
    "ax2.set_xlim(0, len(veloctiyDataFrame))\n",
    "ax2.xaxis.set_ticks_position(\"bottom\")\n",
    "ax2.xaxis.set_label_position(\"bottom\")\n",
    "# Offset the twin axis below the host\n",
    "ax2.spines[\"bottom\"].set_position((\"axes\", -0.25))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(velocity_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot smoothed frames \n",
    "velocity_resampled = downsampledMedian.resample('.2S').bfill()\n",
    "xRangeFrames=(0,len(velocity_resampled))\n",
    "columnToPlot = 'smoothedVelocity'\n",
    "y = velocity_resampled[columnToPlot][xRangeFrames[0]:xRangeFrames[1]]\n",
    "#recording_start_time = datetime.datetime.fromtimestamp(abs(timestampfile[timestampfile['camNum'] == 1]['sysClock'][1]))\n",
    "#plot x axis time\n",
    "recording_start_time = datetime.datetime(1970, 1, 1, hour=0, minute=0, second=0, microsecond=0)\n",
    "x = [recording_start_time+velocity_resampled.index[i] for i in range(len(velocity_resampled.index))][xRangeFrames[0]:xRangeFrames[1]]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax2 = ax1.twiny()\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "\n",
    "myFmt = DateFormatter(\"%M:%S:%ms\")\n",
    "ax1.xaxis.set_major_formatter(myFmt)\n",
    "ax1.plot(x, y)\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "# Move twinned axis ticks and label from top to bottom\n",
    "ax2.set_xlim(0, len(velocity_resampled))\n",
    "ax2.xaxis.set_ticks_position(\"bottom\")\n",
    "ax2.xaxis.set_label_position(\"bottom\")\n",
    "# Offset the twin axis below the host\n",
    "ax2.spines[\"bottom\"].set_position((\"axes\", -0.25))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indiciesRestbin3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move to quest\n",
    "#res_files=8f796c9e-f5c8-11e5-9842-22000b9da45e\n",
    "#quest=d5990400-6d04-11e5-ba46-22000b92c6ec\n",
    "#res_files_base_dir = '8f796c9e-f5c8-11e5-9842-22000b9da45e:/rdss/jma819/fsmresfiles/Projects/JJM/MiniscopeMovies/scope_data/'\n",
    "#quest_dir = 'd5990400-6d04-11e5-ba46-22000b92c6ec:/projects/b1118/behaviorvideos/timestampfiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for session in list(time_stamp_file_locations.keys()):\n",
    "#    transfer_info = res_files_base_dir+time_stamp_file_locations[session]+' '+quest_dir+session+'_timestamp.dat'\n",
    "#    !eval \"globus transfer\" $transfer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##frame by frame alignment to miniscope camera\n",
    "\n",
    "sessions = [f_path.split('/')[-1].rstrip('_raw_trace.csv') for f_path in mm_raw_traces]\n",
    "\n",
    "sessions = ['GRIN039_H14_M8_S53', 'GRIN026_H16_M35_S34', 'GRIN032_H16_M49_S22']\n",
    "\n",
    "for session in sessions:\n",
    "    print(session)\n",
    "    timestampfile = '/projects/b1118/behaviorvideos/timestampfiles/'+session+'_timestamp.dat'\n",
    "    frame_clock_df = pd.read_table(timestampfile)\n",
    "    output_directory = '/projects/b1118/miniscope/analysis/compiled_data/mm_tracking_output/'\n",
    "\n",
    "    Cam0_timestamps = frame_clock_df[frame_clock_df['camNum'] == 0]  \n",
    "    Cam1_timestamps = frame_clock_df[frame_clock_df['camNum'] == 1]\n",
    "    #beavCam is usually faster framerate \n",
    "    if Cam1_timestamps['sysClock'].iloc[1:].diff().mean()<Cam0_timestamps['sysClock'].iloc[1:].diff().mean():\n",
    "        msCam_camnum=0\n",
    "        behavCam_camnum=1\n",
    "    elif Cam0_timestamps['sysClock'].iloc[1:].diff().mean()<Cam1_timestamps['sysClock'].iloc[1:].diff().mean():\n",
    "        msCam_camnum=1\n",
    "        behavCam_camnum=0\n",
    "\n",
    "    raw_trace = pd.read_csv(data_folder+session+'_raw_trace.csv', names=['velocity'])\n",
    "    raw_trace_filtered = pd.read_csv(data_folder+session+'_raw_trace_median_filter.csv', names=['velocity(20_Hz_filtered)'])\n",
    "    speed_trace = pd.read_csv(data_folder+session+'_speedtrace.csv', names=['speed_trace(velocity_5Hz_filtered)'])\n",
    "    raw_traces = pd.concat([raw_trace, raw_trace_filtered], axis=1)\n",
    "\n",
    "    # align the raw traces for comparison\n",
    "\n",
    "    mm_tracking_aligned = dlc.downsample_mmtracking(raw_traces, timestampfile, msCam_camnum, behavCam_camnum)\n",
    "\n",
    "    # convert to timedelta for downsampling \n",
    "    aligned_td = mm_tracking_aligned.set_index(pd.to_timedelta(np.linspace(0, mm_tracking_aligned['sys_clock_behavCam'].values[-1]/1000, len(mm_tracking_aligned)), unit='s'), drop=False)\n",
    "    aligned_td.to_csv(output_directory+session+'_mm_tracking_foranalysis_unsmoothed'+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2pCNMFEAnalysisEnv",
   "language": "python",
   "name": "2pcnmfeanalysisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
